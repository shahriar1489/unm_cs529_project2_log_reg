{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416ef136-4f77-4a4e-84dd-3aa9e0899726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os # used for iterating through file tree\n",
    "#import pandas as pd\n",
    "#import math\n",
    "\n",
    "def dir_to_df():\n",
    "    #if train: # training data\n",
    "\n",
    "    # Directory path\n",
    "    directory = './'\n",
    "\n",
    "    # Initialize an empty list to store file names\n",
    "    au_files = []\n",
    "\n",
    "    # Iterate through the files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file has the \".au\" extension\n",
    "        if filename.endswith(\".au\"):\n",
    "            # Append the file name to the list\n",
    "            au_files.append(filename)\n",
    "\n",
    "    # Print the list of .au files\n",
    "    print(au_files)\n",
    "    return au_files\n",
    "\n",
    "\n",
    "\n",
    "# Path to the audio file\n",
    "#for i in range(101):  # Iterate from 0 to 100\n",
    "    # Format the number with leading zeros to ensure it has 5 digits\n",
    " #   padded_number = str(i).zfill(5)\n",
    "  #  audio_file_suffix = padded_number + \".au\"\n",
    "    #audio_file = 'resources/train/blues/blues.00000.au'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6adec4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interquartile_range(data):\n",
    "  \"\"\"\n",
    "  data : numpy 2D matrix  \n",
    "  \"\"\"\n",
    "\n",
    "  # get upper quartile \n",
    "  Q3 = np.percentile( data , 75, axis=1)\n",
    "\n",
    "  # get lower quartile \n",
    "  Q1 = np.percentile(data, 25, axis=1)\n",
    "\n",
    "  IQR =  Q3 - Q1 \n",
    "  return IQR\n",
    "\n",
    "def get_percentiles(data, percentiles): \n",
    "  \"\"\"\n",
    "\n",
    "  data : 2-D numpy array \n",
    "  percentiles : list w/ percentile values \n",
    "  \n",
    "  Returns: \n",
    "    percentile across each row in the 2-D matrix \n",
    "\n",
    "  \"\"\"\n",
    "  results = []\n",
    "\n",
    "  for p_ in percentiles: \n",
    "\n",
    "    results.append( np.percentile(data, p_, axis=1 ) )\n",
    "\n",
    "\n",
    "  return tuple(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "244f445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_au(au_path):\n",
    "    # Load the audio file using librosa\n",
    "    audio_file = au_path\n",
    "    audio_data, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "    # Extract features using librosa\n",
    "    # Example: compute the Mel-Frequency Cepstral Coefficients (MFCCs)\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n",
    "    stft = np.abs(librosa.stft(y=audio_data))\n",
    "    chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate)\n",
    "    contrast = librosa.feature.spectral_contrast(y=audio_data, sr=sample_rate)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=audio_data)\n",
    "\n",
    "    # Calculate the mean across each row\n",
    "    mean_mfcc = np.mean(mfccs, axis=1)\n",
    "    mean_stft = np.mean(stft, axis=1)\n",
    "    mean_chroma = np.mean(chroma, axis=1)\n",
    "    mean_contrast = np.mean(contrast, axis=1)\n",
    "    mean_zcr = np.mean(zcr, axis=1)\n",
    "\n",
    "\n",
    "    #row_ - \n",
    "\n",
    "\n",
    "\n",
    "    # get minimum and maximum across each row\n",
    "    min_mfcc = np.min(mfccs, axis=1)\n",
    "    min_stft = np.min(stft, axis=1)\n",
    "    min_chroma = np.min(chroma, axis=1)\n",
    "    min_contrast = np.min(contrast, axis=1)\n",
    "    min_zcr = np.min(zcr, axis=1)\n",
    "    \n",
    "    max_mfcc = np.max(mfccs, axis=1)\n",
    "    max_stft = np.max(stft, axis=1)\n",
    "    max_chroma = np.max(chroma, axis=1)\n",
    "    max_contrast = np.max(contrast, axis=1)\n",
    "    max_zcr = np.max(zcr, axis=1)\n",
    "    \n",
    "    \n",
    "    # get median across each row \n",
    "    median_mfcc = np.median(mfccs, axis=1)\n",
    "    median_stft = np.median(stft, axis=1)\n",
    "    median_chroma = np.median(chroma, axis=1)\n",
    "    median_contrast = np.median(contrast, axis=1)\n",
    "    median_zcr = np.median(zcr, axis=1)\n",
    "      \n",
    "\n",
    "    # get interquartile range across each row \n",
    "    iq_mfcc = np.percentile( mfccs , 75, axis=1) - np.percentile( mfccs , 25, axis=1)\n",
    "    iq_stft = np.percentile( stft , 75, axis=1) - np.percentile( stft , 25, axis=1)\n",
    "    iq_chroma = np.percentile( chroma , 75, axis=1) - np.percentile( chroma , 25, axis=1)\n",
    "    iq_contrast = np.percentile( contrast , 75, axis=1) - np.percentile( contrast , 25, axis=1)\n",
    "    iq_zcr = np.percentile( zcr , 75, axis=1) - np.percentile( zcr , 25, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    NOTE: note taking the percentiles of stft.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # get percentiles across each row \n",
    "    percentiles = [12.5, 25.0, 37.5, 62.5, 75.0, 87.5]\n",
    "    \n",
    "    p_12_5_mfcc , p_25_mfcc, p_37_5_mfcc, p_62_5_mfcc , p_75_mfcc , p_87_5_mfcc = get_percentiles(mfccs, percentiles)\n",
    "    p_12_5_chroma , p_25_chroma, p_37_5_chroma, p_62_5_chroma , p_75_chroma , p_87_5_chroma = get_percentiles(chroma, percentiles)\n",
    "    p_12_5_constrast , p_25_contrast, p_37_5_contrast, p_62_5_contrast , p_75_contrast , p_87_5_contrast = get_percentiles(contrast, percentiles)\n",
    "    p_12_5_zcr , p_25_zcr, p_37_5_zcr, p_62_5_zcr , p_75_zcr , p_87_5_zcr = get_percentiles(zcr, percentiles)\n",
    "\n",
    "    print('p_12_5_mfcc shape :', p_12_5_mfcc.shape)\n",
    "    #print(p_12_5_mfcc.shape, p_25_mfcc.shape, p_37_5_mfcc.shape, p_62_5_mfcc.shape , p_75_mfcc.shape , p_87_5_mfcc.shape)\n",
    "\n",
    "    # Reshape to a column vector\n",
    "    #mean_mfcc = mean_mfcc.reshape(-1, 1)\n",
    "    #mean_stft = mean_stft.reshape(-1, 1)\n",
    "    #mean_chroma = mean_chroma.reshape(-1, 1)\n",
    "    #mean_contrast = mean_contrast.reshape(-1, 1)\n",
    "    #mean_zcr = mean_zcr.reshape(-1, 1)\n",
    "\n",
    "    # Concatenate the vectors\n",
    "    concatenated_vectors = np.concatenate((mean_mfcc, mean_stft, \n",
    "                                           mean_chroma, mean_contrast, mean_zcr,\n",
    "                                           \n",
    "                                           min_mfcc, #min_stft, \n",
    "                                           min_chroma, min_contrast, min_zcr,\n",
    "                                           \n",
    "                                           max_mfcc, #max_stft, \n",
    "                                           max_chroma, max_contrast, max_zcr,\n",
    "                                           \n",
    "                                           median_mfcc, #median_stft, \n",
    "                                           median_chroma, median_contrast, median_zcr,\n",
    "\n",
    "                                           iq_mfcc, #iq_stft, \n",
    "                                           iq_chroma, iq_contrast, iq_zcr,\n",
    "                                           \n",
    "                                           p_12_5_mfcc , p_25_mfcc, p_37_5_mfcc, p_62_5_mfcc , p_75_mfcc , p_87_5_mfcc, \n",
    "                                           p_12_5_chroma , p_25_chroma, p_37_5_chroma, p_62_5_chroma , p_75_chroma , p_87_5_chroma,\n",
    "                                           p_12_5_constrast , p_25_contrast, p_37_5_contrast, p_62_5_contrast , p_75_contrast , p_87_5_contrast,\n",
    "                                           p_12_5_zcr , p_25_zcr, p_37_5_zcr, p_62_5_zcr , p_75_zcr , p_87_5_zcr\n",
    "\n",
    "                                           ), axis=0)\n",
    "    print(\"New_vector Shape:\", concatenated_vectors.reshape(-1, 1).shape)\n",
    "\n",
    "    \"\"\"\n",
    "    # Print the shape of the MFCCs\n",
    "    print(\"mean MFCCs Shape:\", mean_mfcc.shape)\n",
    "    #print('-----')\n",
    "    #print(mean_mfcc)\n",
    "    #print('-----')\n",
    "    print(\"mean MFCCs Shape:\", mean_stft.shape)\n",
    "    print(\"mean MFCCs Shape:\", mean_chroma.shape)\n",
    "    print(\"mean MFCCs Shape:\", mean_contrast.shape)\n",
    "    print(\"mean MFCCs Shape:\", mean_zcr.shape)\n",
    "    print(\"New_vector Shape:\", concatenated_vectors.shape)\n",
    "    print(\"New_vector Shape:\", concatenated_vectors.reshape(1,-1).shape)\n",
    "    \"\"\"\n",
    "    #print(mean_mfcc)\n",
    "    return concatenated_vectors.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac576c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
