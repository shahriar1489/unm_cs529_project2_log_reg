{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPOFl8YYQhqD",
        "outputId": "debec1ce-c5d0-4f57-c425-9abc2afcb12e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1AeJ-i5QlrY",
        "outputId": "0d61f5d7-5189-4542-a70c-cbd43479e342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pt\n",
        "\n",
        "from scipy.io import wavfile\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pydub\n",
        "from scipy.io import wavfile\n",
        "\n",
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "import io\n",
        "import sys\n"
      ],
      "metadata": {
        "id": "rYfGFAQuQrDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_FILE_PATH = \"/content/drive/MyDrive/CS529/data/test\""
      ],
      "metadata": {
        "id": "4oOp022tQx7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dir_to_df():\n",
        "    #if train: # training data\n",
        "\n",
        "    # Directory path\n",
        "    directory = './'\n",
        "\n",
        "    # Initialize an empty list to store file names\n",
        "    au_files = []\n",
        "\n",
        "    # Iterate through the files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        # Check if the file has the \".au\" extension\n",
        "        if filename.endswith(\".au\"):\n",
        "            # Append the file name to the list\n",
        "            au_files.append(filename)\n",
        "\n",
        "    # Print the list of .au files\n",
        "    print(au_files)\n",
        "    return au_files\n",
        "\n",
        "\n",
        "\n",
        "# Path to the audio file\n",
        "#for i in range(101):  # Iterate from 0 to 100\n",
        "    # Format the number with leading zeros to ensure it has 5 digits\n",
        " #   padded_number = str(i).zfill(5)\n",
        "  #  audio_file_suffix = padded_number + \".au\"\n",
        "    #audio_file = 'resources/train/blues/blues.00000.au'\n",
        "\n",
        "\n",
        "def get_interquartile_range(data):\n",
        "  \"\"\"\n",
        "  data : numpy 2D matrix\n",
        "  \"\"\"\n",
        "\n",
        "  # get upper quartile\n",
        "  Q3 = np.percentile( data , 75, axis=1)\n",
        "\n",
        "  # get lower quartile\n",
        "  Q1 = np.percentile(data, 25, axis=1)\n",
        "\n",
        "  IQR =  Q3 - Q1\n",
        "  return IQR\n",
        "\n",
        "def get_percentiles(data, percentiles):\n",
        "  \"\"\"\n",
        "\n",
        "  data : 2-D numpy array\n",
        "  percentiles : list w/ percentile values\n",
        "\n",
        "  Returns:\n",
        "    percentile across each row in the 2-D matrix\n",
        "\n",
        "  \"\"\"\n",
        "  results = []\n",
        "\n",
        "  for p_ in percentiles:\n",
        "\n",
        "    results.append( np.percentile(data, p_, axis=1 ) )\n",
        "\n",
        "\n",
        "  return tuple(results)\n",
        "\n",
        "def process_au(au_path):\n",
        "    # Load the audio file using librosa\n",
        "    audio_file = au_path\n",
        "    audio_data, sample_rate = librosa.load(audio_file, sr=None)\n",
        "\n",
        "    # Extract features using librosa\n",
        "    # Example: compute the Mel-Frequency Cepstral Coefficients (MFCCs)\n",
        "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n",
        "    stft = np.abs(librosa.stft(y=audio_data))\n",
        "    chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate)\n",
        "    contrast = librosa.feature.spectral_contrast(y=audio_data, sr=sample_rate)\n",
        "    zcr = librosa.feature.zero_crossing_rate(y=audio_data)\n",
        "\n",
        "    # Calculate the mean across each row\n",
        "    mean_mfcc = np.mean(mfccs, axis=1)\n",
        "    mean_stft = np.mean(stft, axis=1)\n",
        "    mean_chroma = np.mean(chroma, axis=1)\n",
        "    mean_contrast = np.mean(contrast, axis=1)\n",
        "    mean_zcr = np.mean(zcr, axis=1)\n",
        "\n",
        "\n",
        "    # get minimum and maximum across each row\n",
        "    min_mfcc = np.min(mfccs, axis=1)\n",
        "    min_stft = np.min(stft, axis=1)\n",
        "    min_chroma = np.min(chroma, axis=1)\n",
        "    min_contrast = np.min(contrast, axis=1)\n",
        "    min_zcr = np.min(zcr, axis=1)\n",
        "\n",
        "    max_mfcc = np.max(mfccs, axis=1)\n",
        "    max_stft = np.max(stft, axis=1)\n",
        "    max_chroma = np.max(chroma, axis=1)\n",
        "    max_contrast = np.max(contrast, axis=1)\n",
        "    max_zcr = np.max(zcr, axis=1)\n",
        "\n",
        "\n",
        "    # get median across each row\n",
        "    median_mfcc = np.median(mfccs, axis=1)\n",
        "    median_stft = np.median(stft, axis=1)\n",
        "    median_chroma = np.median(chroma, axis=1)\n",
        "    median_contrast = np.median(contrast, axis=1)\n",
        "    median_zcr = np.median(zcr, axis=1)\n",
        "\n",
        "\n",
        "    # get interquartile range across each row\n",
        "    iq_mfcc = np.percentile( mfccs , 75, axis=1) - np.percentile( mfccs , 25, axis=1)\n",
        "    iq_stft = np.percentile( stft , 75, axis=1) - np.percentile( stft , 25, axis=1)\n",
        "    iq_chroma = np.percentile( chroma , 75, axis=1) - np.percentile( chroma , 25, axis=1)\n",
        "    iq_contrast = np.percentile( contrast , 75, axis=1) - np.percentile( contrast , 25, axis=1)\n",
        "    iq_zcr = np.percentile( zcr , 75, axis=1) - np.percentile( zcr , 25, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    NOTE: note taking the percentiles of stft.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # get percentiles across each row\n",
        "    percentiles = [12.5, 25.0, 37.5, 62.5, 75.0, 87.5]\n",
        "\n",
        "    p_12_5_mfcc , p_25_mfcc, p_37_5_mfcc, p_62_5_mfcc , p_75_mfcc , p_87_5_mfcc = get_percentiles(mfccs, percentiles)\n",
        "    p_12_5_chroma , p_25_chroma, p_37_5_chroma, p_62_5_chroma , p_75_chroma , p_87_5_chroma = get_percentiles(chroma, percentiles)\n",
        "    p_12_5_constrast , p_25_contrast, p_37_5_contrast, p_62_5_contrast , p_75_contrast , p_87_5_contrast = get_percentiles(contrast, percentiles)\n",
        "    p_12_5_zcr , p_25_zcr, p_37_5_zcr, p_62_5_zcr , p_75_zcr , p_87_5_zcr = get_percentiles(zcr, percentiles)\n",
        "\n",
        "    #print('p_12_5_mfcc shape :', p_12_5_mfcc.shape)\n",
        "    #print(p_12_5_mfcc.shape, p_25_mfcc.shape, p_37_5_mfcc.shape, p_62_5_mfcc.shape , p_75_mfcc.shape , p_87_5_mfcc.shape)\n",
        "\n",
        "    # Reshape to a column vector\n",
        "    #mean_mfcc = mean_mfcc.reshape(-1, 1)\n",
        "    #mean_stft = mean_stft.reshape(-1, 1)\n",
        "    #mean_chroma = mean_chroma.reshape(-1, 1)\n",
        "    #mean_contrast = mean_contrast.reshape(-1, 1)\n",
        "    #mean_zcr = mean_zcr.reshape(-1, 1)\n",
        "\n",
        "    # Concatenate the vectors\n",
        "    concatenated_vectors = np.concatenate((mean_mfcc, mean_stft,\n",
        "                                           mean_chroma, mean_contrast, mean_zcr,\n",
        "\n",
        "                                           min_mfcc, #min_stft,\n",
        "                                           min_chroma, min_contrast, min_zcr,\n",
        "\n",
        "                                           max_mfcc, #max_stft,\n",
        "                                           max_chroma, max_contrast, max_zcr,\n",
        "\n",
        "                                           median_mfcc, #median_stft,\n",
        "                                           median_chroma, median_contrast, median_zcr,\n",
        "\n",
        "                                           iq_mfcc, #iq_stft,\n",
        "                                           iq_chroma, iq_contrast, iq_zcr,\n",
        "\n",
        "                                           p_12_5_mfcc , p_25_mfcc, p_37_5_mfcc, p_62_5_mfcc , p_75_mfcc , p_87_5_mfcc,\n",
        "                                           p_12_5_chroma , p_25_chroma, p_37_5_chroma, p_62_5_chroma , p_75_chroma , p_87_5_chroma,\n",
        "                                           p_12_5_constrast , p_25_contrast, p_37_5_contrast, p_62_5_contrast , p_75_contrast , p_87_5_contrast,\n",
        "                                           p_12_5_zcr , p_25_zcr, p_37_5_zcr, p_62_5_zcr , p_75_zcr , p_87_5_zcr\n",
        "\n",
        "                                           ), axis=0)\n",
        "    print(\"New_vector Shape:\", concatenated_vectors.shape)\n",
        "\n",
        "\n",
        "    return concatenated_vectors #.reshape(-1, 1)\n",
        "\n",
        "    #print(\"hello\")\n"
      ],
      "metadata": {
        "id": "RfB8RFNKRBt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This function only supports the logic behind creating train data w/ label\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def create_test_dataset(path):\n",
        "\n",
        "  df_list = []\n",
        "\n",
        "  # check if a path exist\n",
        "  #for label in labels :  # there are no labels in the test directory\n",
        "\n",
        "    #print(label)\n",
        "  data = []\n",
        "\n",
        "  # create new path\n",
        "  #label_path = os.path.join(path, label)\n",
        "  #print(label_path)\n",
        "\n",
        "  # after the path is created, read each .au files in that PATH\n",
        "  for filename in os.listdir(path):\n",
        "    if filename.endswith('.au'):\n",
        "\n",
        "      # Construct the full path to the audio file\n",
        "      audio_file_path = os.path.join(path, filename)\n",
        "      #print(audio_file_path)\n",
        "\n",
        "      # apply the process_au\n",
        "      data.append( process_au(audio_file_path) )\n",
        "\n",
        "  data = pd.DataFrame( np.array(data) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #df_list.append(data)\n",
        "\n",
        "\n",
        "  # At this point, df is list of df with of shape (90, 1389) for train data.\n",
        "  # I want them to merge into a single dataframe with shape (90*length_of_df. 1389)\n",
        "  #df =  pd.concat(data, ignore_index=True)\n",
        "\n",
        "  return data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KUgzGOAhRN4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "test_df = create_test_dataset(TEST_FILE_PATH)\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wVs-xuBRT7v",
        "outputId": "2ca66b11-21d2-4a3a-c699-1aecdacf7f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n",
            "New_vector Shape: (1388,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJd9sK_LSNRA",
        "outputId": "f901a75f-9409-4050-ef49-763552de8833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1388)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FOLDER_PATH = ( os.path.join( os.getcwd(), 'drive', 'MyDrive', 'CS529' ))"
      ],
      "metadata": {
        "id": "bNUSswzzTJFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv(os.path.join(FOLDER_PATH, 'test.csv'), index=False)"
      ],
      "metadata": {
        "id": "NIau4sPDTg0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B5on4ZpLTnlP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}